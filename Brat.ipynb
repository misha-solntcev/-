{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcqMbyJxP619yZGL2aig05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misha-solntcev/-/blob/master/Brat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas\n",
        "! pip install natasha"
      ],
      "metadata": {
        "id": "yWc8zIR0x0-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/Братищенко/ЗаявкиТест.xlsx')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ob-ZU7xHyKLk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Братищенко/StopListRus.txt', 'r') as file:\n",
        "    stoplist = list(file)\n",
        "\n",
        "stoplist = [x[:-1] for x in stoplist]"
      ],
      "metadata": {
        "id": "ZWmETIujz9_n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Doc, Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "def text2lemmas(text):\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for token in doc.tokens:\n",
        "        token.lemmatize(morph_vocab)\n",
        "    return ' '.join([token.lemma for token in doc.tokens])\n"
      ],
      "metadata": {
        "id": "NhDDnXSo0Rmj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Лемматизация\n",
        "df['lemmas'] = [text2lemmas(item) for item in df['КРАТКОЕ_ОПИСАНИЕ']]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZtBspaxQ22sS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторайзер\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer(stop_words=stoplist, token_pattern='[А-Яа-я]\\\\w+')"
      ],
      "metadata": {
        "id": "kkzOZguw6mf4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Мешок слов\n",
        "bow = count_vectorizer.fit_transform(df['lemmas'])"
      ],
      "metadata": {
        "id": "e8Z0kdkB7ZQH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь корпуса\n",
        "v = count_vectorizer.vocabulary_"
      ],
      "metadata": {
        "id": "g417nHO875C0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Матрица частот корпуса\n",
        "M = bow.todense()\n",
        "# print(M)\n",
        "\n",
        "# вычисление абсолютных частот по матрице\n",
        "f_term = bow.sum(axis=0)\n",
        "# print(f_term)\n",
        "\n",
        "# получение индексов сумм, отсортированных по убыванию\n",
        "term_i = f_term.argsort()[0,::-1]\n",
        "# term_i\n",
        "\n",
        "# создание словаря индекс: слово\n",
        "i_term = dict(zip(count_vectorizer.vocabulary_.values(), count_vectorizer.vocabulary_.keys()))\n",
        "# i_term\n",
        "\n",
        "# список слов по убыванию частот\n",
        "word_f = [[i_term[term_i[0,j]], f_term[0,term_i[0,j]]] for j in range(term_i.shape[1])]\n",
        "# word_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt726cOg8LEM",
        "outputId": "f96e0ce4-2819-45fa-c5c5-3b2c2685ae3d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 0]]\n"
          ]
        }
      ]
    }
  ]
}